# -*- coding: utf-8 -*-
"""BioLingo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cXW_n3uL3Z7mHUFLdv3RbQ2nCmNoKna4
"""

# ============================================================
# üåç BioLingo - Identifica√ß√£o de Esp√©cies (Imagem + √Åudio)
# ============================================================

# 1Ô∏è‚É£ Instalar depend√™ncias
!pip install tensorflow pandas scikit-learn librosa pillow matplotlib openai

# 2Ô∏è‚É£ Importa√ß√µes
import os, numpy as np, pandas as pd, librosa, librosa.display, matplotlib.pyplot as plt
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.optimizers import Adam
from PIL import Image
from io import BytesIO
import zipfile, requests
from google.colab import files
from openai import OpenAI

# ============================================================
# 3Ô∏è‚É£ Configura√ß√£o
# ============================================================
os.environ["BIO_API_KEY"] = "sk-865e2f5d74454da8926d27e093eba545"

client = OpenAI(
    api_key=os.getenv("BIO_API_KEY"),
    base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
)

# ============================================================
# 4Ô∏è‚É£ Upload do dataset (ZIP ou CSV)
# ============================================================
print("üì§ Faz upload do dataset (pode ser .zip ou .csv)")
uploaded = files.upload()
dataset_path = list(uploaded.keys())[0]

# Verifica tipo de ficheiro
if dataset_path.endswith(".zip"):
    print("üì¶ Ficheiro ZIP detectado, a extrair...")
    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:
        zip_ref.extractall("/content/")
        extracted = zip_ref.namelist()
        print("üìÇ Conte√∫do extra√≠do:", extracted)
        csv_candidates = [f for f in extracted if f.endswith(".csv")]
        csv_path = os.path.join("/content", csv_candidates[0]) if csv_candidates else None
elif dataset_path.endswith(".csv"):
    csv_path = dataset_path
else:
    raise ValueError("Por favor envia um ficheiro .csv ou .zip contendo o dataset.")

# Ler CSV com toler√¢ncia de codifica√ß√£o
try:
    df = pd.read_csv(csv_path, encoding="utf-8")
except UnicodeDecodeError:
    df = pd.read_csv(csv_path, encoding="latin1")

print("‚úÖ Dataset carregado:", csv_path)
print("Esp√©cies dispon√≠veis:", df["nome_comum"].unique())

# ============================================================
# 5Ô∏è‚É£ Upload e classifica√ß√£o de IMAGEM
# ============================================================
print("\nüì∏ Faz upload de uma imagem de esp√©cie (jpg/png)")
img_upload = files.upload()
img_path = list(img_upload.keys())[0]

# Pr√©-processar imagem
img = Image.open(img_path).resize((224,224))
img_array = np.expand_dims(np.array(img)/255.0, axis=0)

# Modelo base EfficientNet (Transfer Learning simulado)
base_model = EfficientNetB0(include_top=False, input_shape=(224,224,3),
                             weights="imagenet", pooling="avg")

model_img = Sequential([
    base_model,
    Dropout(0.3),
    Dense(128, activation="relu"),
    Dense(len(df["nome_comum"].unique()), activation="softmax")
])

# Simular predi√ß√£o
pred_img = model_img.predict(img_array)
predicted_label_img = df["nome_comum"].iloc[np.argmax(pred_img)]
print(f"üîç Predi√ß√£o (imagem): {predicted_label_img}")

# ============================================================
# 6Ô∏è‚É£ Upload e classifica√ß√£o de √ÅUDIO
# ============================================================
print("\nüéôÔ∏è Faz upload de um ficheiro de √°udio (.wav ou .mp3)")
audio_upload = files.upload()
audio_path = list(audio_upload.keys())[0]

# Converter √°udio em espectrograma
y, sr = librosa.load(audio_path, sr=22050)
mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
mel_db = librosa.power_to_db(mel, ref=np.max)

plt.figure(figsize=(10, 4))
librosa.display.specshow(mel_db, sr=sr, x_axis='time', y_axis='mel')
plt.title('Espectrograma do √Åudio')
plt.colorbar(format='%+2.0f dB')
plt.show()

# Pr√©-processar espectrograma
mel_img = np.expand_dims(np.expand_dims(mel_db, axis=-1), axis=0)

# CNN simples para espectrograma
model_audio = Sequential([
    Conv2D(16, (3,3), activation='relu', input_shape=(mel_db.shape[0], mel_db.shape[1], 1)),
    MaxPooling2D(2,2),
    Conv2D(32, (3,3), activation='relu'),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(len(df["nome_comum"].unique()), activation='softmax')
])

pred_audio = model_audio.predict(mel_img)
predicted_label_audio = df["nome_comum"].iloc[np.argmax(pred_audio)]
print(f"üîä Predi√ß√£o (√°udio): {predicted_label_audio}")

# ============================================================
# 7Ô∏è‚É£ Verifica√ß√£o e Identifica√ß√£o
# ============================================================
descricao = (
    f"A imagem sugeriu: {predicted_label_img}. "
    f"O √°udio sugeriu: {predicted_label_audio}. "
    "Confirma qual √© a esp√©cie mais prov√°vel com base em fauna angolana."
)

print("\nü§ñ Consultando o modelo BioLingo...")
response = client.chat.completions.create(
    model="qwen-plus",
    messages=[
        {"role": "system", "content": "Tu √©s um bi√≥logo especialista em esp√©cies africanas e angolanas."},
        {"role": "user", "content": descricao}
    ]
)

print("\nü¶ú Resposta do BioLingo:")
print(response.choices[0].message.content)